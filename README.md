# Distributed Sales Data Analysis System

## ğŸ“Œ Overview

This project demonstrates a distributed system that processes a large CSV dataset (5 million sales transactions) using multiple Python worker nodes communicating with a central server via TCP sockets.

## âš™ï¸ Technologies Used

- Python 3.8+
- Pandas
- SQLite
- TCP Sockets
- Pickle (Serialization)

## ğŸ“ Project Structure
sales_distributed_analysis/
â”œâ”€â”€ config.py

â”œâ”€â”€ db_handler.py

â”œâ”€â”€ server.py

â”œâ”€â”€ worker.py

â”œâ”€â”€ sample_data.csv

â””â”€â”€ results.db

ğŸš€ How It Works
1. Data Loading & Chunking: The server loads the full sales CSV and splits it into chunks.
2. Parallel Processing: Each worker connects to the server, receives a chunk, processes sales data (computing aggregates like total sales, min/max/avg prices), and sends back results.
3. Result Aggregation: The server collects results from all workers and stores them in the SQLite database with timestamps.
4. Exploratory Data Analysis: The eda.py script uses the aggregated results and original sales data to generate insightful visualizations â€” including worker performance, sales trends over time, and price distributions.

ğŸ“Š Visualizations Include
1. Rows processed by each worker (bar chart)
2. Sales contribution by worker (pie chart)
3. Price metrics (average with min/max error bars per worker)
4. Monthly and yearly sales trends with smoothing and peak highlights

ğŸ’¡ Notes
- The system supports easy scaling by adding more worker nodes.
- Database timestamps allow tracking when each chunk was processed.
- The EDA script can be run independently to generate up-to-date visualizations.
